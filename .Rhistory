Title = word(train$Name, start = 1, sep = fixed(".")))
train$Title <- train$Title %>%
str_replace("[.]", "") %>%
word(start = -1) %>%
as.factor(.)
# Remove uncommon titles
uncommon <- train %>%
group_by(Title) %>%
count() %>%
filter (n >=5)
levels(train$Title) <- c(levels(train$Title), "Other")
train$Title[!(train$Title %in% uncommon$Title)] <- as.factor("Other")
train$Title <- droplevels.data.frame(train)$Title
# Update embarkment location to factor
train$Embarked <- as.factor(train$Embarked)
# Gender to factor
train$Sex <- as.factor(train$Sex)
train$FamilySize <- train$Parch + train$SibSp + 1
summary(train)
train %>%
filter(Surname == "Andersson") %>%
select(Name, FamilySize, Survived, SibSp, Parch)
clean_age <- function(df) {
# Turns missing values into the average for the column.
NA2mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
df[,'Age'] <- lapply(df[,'Age'], NA2mean)
return(df)
}
clean_embarkment <- function(df) {
# The most people embarked from 'S', so I'm just setting
# the two missing values to 'S'.
df[is.na(df[,'Embarked']), 'Embarked'] <- 'S'
return (df)
}
test <- clean_age(test)
train <- clean_age(train)
test <- clean_embarkment(test)
train <- clean_embarkment(train)
scaler <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}
cleanse <- function(df) {
# Remove character variables
df <- subset(df, select = -c(Name, Ticket, Cabin, Surname))
# If it's a prediction set or otherwise, break it out
if('Survived' %in% colnames(df)){
id <- select(df, Survived, PassengerId)
df <- subset(df, select = -c(Survived, PassengerId))
} else {
id <- select(df, PassengerId)
df <- subset(df, select = -c(PassengerId))
}
# Convert factors to numbers
factname = c('Embarked', 'Title', 'Sex')
df[,factname] <- lapply(df[,factname] , as.integer)
# Scale variables
df <- as.tibble(map(df, na.rm = TRUE, scaler))
# Again, separate by labeled or not
if('Survived' %in% colnames(id)){
df$PassengerId <- id$PassengerId
df$Survived <- id$Survived
} else {
df$PassengerId <- id$PassengerId
}
return(df)
}
train_scl <- cleanse(train)
test_scl <- cleanse(test)
summary(train_scl)
logit <- glm(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
family = binomial(),
data = train_scl,
na.action = na.omit)
summary(logit)
# Now we predict using the model
threshold <- 0.5
logit_pred <- predict(logit, newdata = test_scl, type = 'response')
hist(logit_pred)
logit_pred <- ifelse(logit_pred > threshold, 1, 0)
# If we're missing data, predict 0.
logit_pred[is.na(logit_pred)] <- 0
summary(logit_pred)
all <- data.frame(test$PassengerId, logit_pred)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/logit_prediction.csv")
library(neuralnet)
set.seed(91)
# Model the neural network
nnet <- neuralnet(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
hidden = c(10,15,10),
threshold = 0.01,
stepmax = 400000000,
data = train_scl,
lifesign = 'full')
library(neuralnet)
set.seed(91)
# Model the neural network
nnet <- neuralnet(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
hidden = c(10,15,10),
threshold = 0.035,
stepmax = 400000000,
data = train_scl,
lifesign = 'full')
# Predict the test set
nnet.c <- compute(nnet, test_scl[,1:8])
nnet.c <- nnet.c$net.result
hist(nnet.c)
nnet.c <- ifelse(nnet.c > threshold, 1, 0)
# If we're missing data, predict 0.
nnet.c[is.na(nnet.c)] <- 0
summary(nnet.c)
all <- data.frame(test$PassengerId, nnet.c)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/nnet_prediction.csv")
# Libraries
library(tidyverse)
library(stringr)
# Load data
train <- read_csv("../../data/Titanic/train.csv")
test <- read_csv("../../data/Titanic/test.csv")
str(train)
# Do it with test and train, don't want to reconcile them later.
test <- test %>%
mutate(Surname = as.factor(word(test$Name, sep = fixed(","))),
Title = word(test$Name, start = 1, sep = fixed(".")))
test$Title <- test$Title %>%
str_replace("[.]", "") %>%
word(start = -1) %>%
as.factor(.)
# Remove uncommon titles
uncommon <- test %>%
group_by(Title) %>%
count() %>%
filter (n >=5)
levels(test$Title) <- c(levels(test$Title), "Other")
test$Title[!(test$Title %in% uncommon$Title)] <- as.factor("Other")
test$Title <- droplevels.data.frame(test)$Title
# Update embarkment location to factor
test$Embarked <- as.factor(test$Embarked)
# Gender to factor
test$Sex <- as.factor(test$Sex)
test$FamilySize <- test$Parch + test$SibSp + 1
# Change training dataset
train <- train %>%
mutate(Surname = as.factor(word(train$Name, sep = fixed(","))),
Title = word(train$Name, start = 1, sep = fixed(".")))
train$Title <- train$Title %>%
str_replace("[.]", "") %>%
word(start = -1) %>%
as.factor(.)
# Remove uncommon titles
uncommon <- train %>%
group_by(Title) %>%
count() %>%
filter (n >=5)
levels(train$Title) <- c(levels(train$Title), "Other")
train$Title[!(train$Title %in% uncommon$Title)] <- as.factor("Other")
train$Title <- droplevels.data.frame(train)$Title
# Update embarkment location to factor
train$Embarked <- as.factor(train$Embarked)
# Gender to factor
train$Sex <- as.factor(train$Sex)
train$FamilySize <- train$Parch + train$SibSp + 1
summary(train)
train %>%
filter(Surname == "Andersson") %>%
select(Name, FamilySize, Survived, SibSp, Parch)
clean_age <- function(df) {
# Turns missing values into the average for the column.
NA2mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
df[,'Age'] <- lapply(df[,'Age'], NA2mean)
return(df)
}
clean_embarkment <- function(df) {
# The most people embarked from 'S', so I'm just setting
# the two missing values to 'S'.
df[is.na(df[,'Embarked']), 'Embarked'] <- 'S'
return (df)
}
test <- clean_age(test)
train <- clean_age(train)
test <- clean_embarkment(test)
train <- clean_embarkment(train)
scaler <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}
cleanse <- function(df) {
# Remove character variables
df <- subset(df, select = -c(Name, Ticket, Cabin, Surname))
# If it's a prediction set or otherwise, break it out
if('Survived' %in% colnames(df)){
id <- select(df, Survived, PassengerId)
df <- subset(df, select = -c(Survived, PassengerId))
} else {
id <- select(df, PassengerId)
df <- subset(df, select = -c(PassengerId))
}
# Convert factors to numbers
factname = c('Embarked', 'Title', 'Sex')
df[,factname] <- lapply(df[,factname] , as.integer)
# Scale variables
df <- as.tibble(map(df, na.rm = TRUE, scaler))
# Again, separate by labeled or not
if('Survived' %in% colnames(id)){
df$PassengerId <- id$PassengerId
df$Survived <- id$Survived
} else {
df$PassengerId <- id$PassengerId
}
return(df)
}
train_scl <- cleanse(train)
test_scl <- cleanse(test)
summary(train_scl)
logit <- glm(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
family = binomial(),
data = train_scl,
na.action = na.omit)
summary(logit)
# Now we predict using the model
threshold <- 0.5
logit_pred <- predict(logit, newdata = test_scl, type = 'response')
hist(logit_pred)
logit_pred <- ifelse(logit_pred > threshold, 1, 0)
# If we're missing data, predict 0.
logit_pred[is.na(logit_pred)] <- 0
summary(logit_pred)
all <- data.frame(test$PassengerId, logit_pred)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/logit_prediction.csv")
library(neuralnet)
set.seed(91)
# Model the neural network
nnet <- neuralnet(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
hidden = c(30),
threshold = 0.035,
stepmax = 400000000,
data = train_scl,
lifesign = 'full')
# Predict the test set
nnet.c <- compute(nnet, test_scl[,1:8])
nnet.c <- nnet.c$net.result
hist(nnet.c)
nnet.c <- ifelse(nnet.c > threshold, 1, 0)
# If we're missing data, predict 0.
nnet.c[is.na(nnet.c)] <- 0
summary(nnet.c)
all <- data.frame(test$PassengerId, nnet.c)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/nnet_prediction.csv")
# Libraries
library(tidyverse)
library(stringr)
# Load data
train <- read_csv("../../data/Titanic/train.csv")
test <- read_csv("../../data/Titanic/test.csv")
str(train)
# Do it with test and train, don't want to reconcile them later.
test <- test %>%
mutate(Surname = as.factor(word(test$Name, sep = fixed(","))),
Title = word(test$Name, start = 1, sep = fixed(".")))
test$Title <- test$Title %>%
str_replace("[.]", "") %>%
word(start = -1) %>%
as.factor(.)
# Remove uncommon titles
uncommon <- test %>%
group_by(Title) %>%
count() %>%
filter (n >=5)
levels(test$Title) <- c(levels(test$Title), "Other")
test$Title[!(test$Title %in% uncommon$Title)] <- as.factor("Other")
test$Title <- droplevels.data.frame(test)$Title
# Update embarkment location to factor
test$Embarked <- as.factor(test$Embarked)
# Gender to factor
test$Sex <- as.factor(test$Sex)
test$FamilySize <- test$Parch + test$SibSp + 1
# Change training dataset
train <- train %>%
mutate(Surname = as.factor(word(train$Name, sep = fixed(","))),
Title = word(train$Name, start = 1, sep = fixed(".")))
train$Title <- train$Title %>%
str_replace("[.]", "") %>%
word(start = -1) %>%
as.factor(.)
# Remove uncommon titles
uncommon <- train %>%
group_by(Title) %>%
count() %>%
filter (n >=5)
levels(train$Title) <- c(levels(train$Title), "Other")
train$Title[!(train$Title %in% uncommon$Title)] <- as.factor("Other")
train$Title <- droplevels.data.frame(train)$Title
# Update embarkment location to factor
train$Embarked <- as.factor(train$Embarked)
# Gender to factor
train$Sex <- as.factor(train$Sex)
train$FamilySize <- train$Parch + train$SibSp + 1
summary(train)
train %>%
filter(Surname == "Andersson") %>%
select(Name, FamilySize, Survived, SibSp, Parch)
clean_age <- function(df) {
# Turns missing values into the average for the column.
NA2mean <- function(x) replace(x, is.na(x), mean(x, na.rm = TRUE))
df[,'Age'] <- lapply(df[,'Age'], NA2mean)
return(df)
}
clean_embarkment <- function(df) {
# The most people embarked from 'S', so I'm just setting
# the two missing values to 'S'.
df[is.na(df[,'Embarked']), 'Embarked'] <- 'S'
return (df)
}
test <- clean_age(test)
train <- clean_age(train)
test <- clean_embarkment(test)
train <- clean_embarkment(train)
scaler <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}
cleanse <- function(df) {
# Remove character variables
df <- subset(df, select = -c(Name, Ticket, Cabin, Surname))
# If it's a prediction set or otherwise, break it out
if('Survived' %in% colnames(df)){
id <- select(df, Survived, PassengerId)
df <- subset(df, select = -c(Survived, PassengerId))
} else {
id <- select(df, PassengerId)
df <- subset(df, select = -c(PassengerId))
}
# Convert factors to numbers
factname = c('Embarked', 'Title', 'Sex')
df[,factname] <- lapply(df[,factname] , as.integer)
# Scale variables
df <- as.tibble(map(df, na.rm = TRUE, scaler))
# Again, separate by labeled or not
if('Survived' %in% colnames(id)){
df$PassengerId <- id$PassengerId
df$Survived <- id$Survived
} else {
df$PassengerId <- id$PassengerId
}
return(df)
}
train_scl <- cleanse(train)
test_scl <- cleanse(test)
summary(train_scl)
logit <- glm(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
family = binomial(),
data = train_scl,
na.action = na.omit)
summary(logit)
# Now we predict using the model
threshold <- 0.5
logit_pred <- predict(logit, newdata = test_scl, type = 'response')
hist(logit_pred)
logit_pred <- ifelse(logit_pred > threshold, 1, 0)
# If we're missing data, predict 0.
logit_pred[is.na(logit_pred)] <- 0
summary(logit_pred)
all <- data.frame(test$PassengerId, logit_pred)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/logit_prediction.csv")
library(neuralnet)
set.seed(91)
# Model the neural network
nnet <- neuralnet(Survived ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title,
hidden = c(30,30),
threshold = 0.035,
stepmax = 400000000,
data = train_scl,
lifesign = 'full')
# Predict the test set
nnet.c <- compute(nnet, test_scl[,1:8])
nnet.c <- nnet.c$net.result
hist(nnet.c)
nnet.c <- ifelse(nnet.c > threshold, 1, 0)
# If we're missing data, predict 0.
nnet.c[is.na(nnet.c)] <- 0
summary(nnet.c)
all <- data.frame(test$PassengerId, nnet.c)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/nnet_prediction.csv")
all <- data.frame(test$PassengerId, nnet.c)
colnames(all) <- c("PassengerID", "Survived")
write_csv(all, "../../data/Titanic/predictions/nnet_prediction.csv")
library(blogdown)
install_theme("digitalcraftsman/hugo-steam-theme")
serve_site()
build_site()
install_theme("MunifTanjim/minimo")
build_site()
serve_site()
build_site()
serve_site()
build_site()
serve_site()
serve_site()
serve_site()
serve_site()
build_site()
serve_site()
install_theme("nishanths/cocoa-hugo-theme")
serve_site()
install_theme("gcushen/hugo-academic")
serve_site()
install_theme("gcushen/hugo-academic")
serve_site()
install_theme("lambdafu/hugo-finite")
serve_site()
build_site()
serve_site()
build_site()
build_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
library(blogdown)
build_site()
library(blogdown)
?build_site
blogdown.publishDir
library(blogdown)
new_post()
library(blogdown)
build_site()
build_site()
build_site()
serve_site()
build_site()
library(blogdown)
new_post("A Brief Paper on Cointegration in Crude Oil")
build_site()
library(tufte)
tufte
tufte_handout()
library(blogdown)
serve_site()
licence()
library(blogdown)
new_post("Perfect Numbers")
build_site()
serve_site()
serve_site()
blogdown::serve_site()
blogdown::build_site()
library(blogdown)
build_site()
serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::new_post("English Pronunciation")
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::build_site()
library(blogdown)
serve_site()
build_site()
blogdown::new_post("The American Dream")
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
x <- c(1.4, 1.43, 1.44, 1.44, 1.44, 1.45,
1.45, 1.47, 1.48, 1.5)
mean(x)
std(x)
stdev(x)
sd(x)
confint(x)
1.833 * (sqrt(1.45)/sqrt(10))
1.833 * (sqrt(0.028)/sqrt(10))
1.45+0.097
1.45-0.097
x <- c(.7,.7,.72,.72,.72,.72,
.74,.75,.75,.75,
.76,.77,.82)
mean(x)
hist(x)
sd(x)
sqrt(2.45)/sqrt(40)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
ci
ci*2
source('~/.active-rstudio-document', echo=TRUE)
install.packages("blogdown")
blogdown:::new_post_addin()
blogdown:::serve_site()
blogdown::build_site()
library(blogdown)
new_post("Technical Analysis")
